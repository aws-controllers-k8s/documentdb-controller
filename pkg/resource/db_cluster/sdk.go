// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License"). You may
// not use this file except in compliance with the License. A copy of the
// License is located at
//
//     http://aws.amazon.com/apache2.0/
//
// or in the "license" file accompanying this file. This file is distributed
// on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
// express or implied. See the License for the specific language governing
// permissions and limitations under the License.

// Code generated by ack-generate. DO NOT EDIT.

package db_cluster

import (
	"context"
	"errors"
	"fmt"
	"math"
	"reflect"
	"strings"

	ackv1alpha1 "github.com/aws-controllers-k8s/runtime/apis/core/v1alpha1"
	ackcompare "github.com/aws-controllers-k8s/runtime/pkg/compare"
	ackcondition "github.com/aws-controllers-k8s/runtime/pkg/condition"
	ackerr "github.com/aws-controllers-k8s/runtime/pkg/errors"
	ackrequeue "github.com/aws-controllers-k8s/runtime/pkg/requeue"
	ackrtlog "github.com/aws-controllers-k8s/runtime/pkg/runtime/log"
	"github.com/aws/aws-sdk-go-v2/aws"
	svcsdk "github.com/aws/aws-sdk-go-v2/service/docdb"
	svcsdktypes "github.com/aws/aws-sdk-go-v2/service/docdb/types"
	smithy "github.com/aws/smithy-go"
	corev1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"

	svcapitypes "github.com/aws-controllers-k8s/documentdb-controller/apis/v1alpha1"
)

// Hack to avoid import errors during build...
var (
	_ = &metav1.Time{}
	_ = strings.ToLower("")
	_ = &svcsdk.Client{}
	_ = &svcapitypes.DBCluster{}
	_ = ackv1alpha1.AWSAccountID("")
	_ = &ackerr.NotFound
	_ = &ackcondition.NotManagedMessage
	_ = &reflect.Value{}
	_ = fmt.Sprintf("")
	_ = &ackrequeue.NoRequeue{}
	_ = &aws.Config{}
)

// sdkFind returns SDK-specific information about a supplied resource
func (rm *resourceManager) sdkFind(
	ctx context.Context,
	r *resource,
) (latest *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkFind")
	defer func() {
		exit(err)
	}()
	// If any required fields in the input shape are missing, AWS resource is
	// not created yet. Return NotFound here to indicate to callers that the
	// resource isn't yet created.
	if rm.requiredFieldsMissingFromReadManyInput(r) {
		return nil, ackerr.NotFound
	}

	input, err := rm.newListRequestPayload(r)
	if err != nil {
		return nil, err
	}
	var resp *svcsdk.DescribeDBClustersOutput
	resp, err = rm.sdkapi.DescribeDBClusters(ctx, input)
	rm.metrics.RecordAPICall("READ_MANY", "DescribeDBClusters", err)
	if err != nil {
		var awsErr smithy.APIError
		if errors.As(err, &awsErr) && awsErr.ErrorCode() == "DBClusterNotFoundFault" {
			return nil, ackerr.NotFound
		}
		return nil, err
	}

	// Merge in the information we read from the API call above to the copy of
	// the original Kubernetes object we passed to the function
	ko := r.ko.DeepCopy()

	found := false
	for _, elem := range resp.DBClusters {
		if elem.AssociatedRoles != nil {
			f0 := []*svcapitypes.DBClusterRole{}
			for _, f0iter := range elem.AssociatedRoles {
				f0elem := &svcapitypes.DBClusterRole{}
				if f0iter.RoleArn != nil {
					f0elem.RoleARN = f0iter.RoleArn
				}
				if f0iter.Status != nil {
					f0elem.Status = f0iter.Status
				}
				f0 = append(f0, f0elem)
			}
			ko.Status.AssociatedRoles = f0
		} else {
			ko.Status.AssociatedRoles = nil
		}
		if elem.AvailabilityZones != nil {
			ko.Spec.AvailabilityZones = aws.StringSlice(elem.AvailabilityZones)
		} else {
			ko.Spec.AvailabilityZones = nil
		}
		if elem.BackupRetentionPeriod != nil {
			backupRetentionPeriodCopy := int64(*elem.BackupRetentionPeriod)
			ko.Spec.BackupRetentionPeriod = &backupRetentionPeriodCopy
		} else {
			ko.Spec.BackupRetentionPeriod = nil
		}
		if elem.CloneGroupId != nil {
			ko.Status.CloneGroupID = elem.CloneGroupId
		} else {
			ko.Status.CloneGroupID = nil
		}
		if elem.ClusterCreateTime != nil {
			ko.Status.ClusterCreateTime = &metav1.Time{*elem.ClusterCreateTime}
		} else {
			ko.Status.ClusterCreateTime = nil
		}
		if elem.DBClusterArn != nil {
			if ko.Status.ACKResourceMetadata == nil {
				ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
			}
			tmpARN := ackv1alpha1.AWSResourceName(*elem.DBClusterArn)
			ko.Status.ACKResourceMetadata.ARN = &tmpARN
		}
		if elem.DBClusterIdentifier != nil {
			ko.Spec.DBClusterIdentifier = elem.DBClusterIdentifier
		} else {
			ko.Spec.DBClusterIdentifier = nil
		}
		if elem.DBClusterMembers != nil {
			f7 := []*svcapitypes.DBClusterMember{}
			for _, f7iter := range elem.DBClusterMembers {
				f7elem := &svcapitypes.DBClusterMember{}
				if f7iter.DBClusterParameterGroupStatus != nil {
					f7elem.DBClusterParameterGroupStatus = f7iter.DBClusterParameterGroupStatus
				}
				if f7iter.DBInstanceIdentifier != nil {
					f7elem.DBInstanceIdentifier = f7iter.DBInstanceIdentifier
				}
				if f7iter.IsClusterWriter != nil {
					f7elem.IsClusterWriter = f7iter.IsClusterWriter
				}
				if f7iter.PromotionTier != nil {
					promotionTierCopy := int64(*f7iter.PromotionTier)
					f7elem.PromotionTier = &promotionTierCopy
				}
				f7 = append(f7, f7elem)
			}
			ko.Status.DBClusterMembers = f7
		} else {
			ko.Status.DBClusterMembers = nil
		}
		if elem.DBClusterParameterGroup != nil {
			ko.Status.DBClusterParameterGroup = elem.DBClusterParameterGroup
		} else {
			ko.Status.DBClusterParameterGroup = nil
		}
		if elem.DBSubnetGroup != nil {
			ko.Status.DBSubnetGroup = elem.DBSubnetGroup
		} else {
			ko.Status.DBSubnetGroup = nil
		}
		if elem.DbClusterResourceId != nil {
			ko.Status.DBClusterResourceID = elem.DbClusterResourceId
		} else {
			ko.Status.DBClusterResourceID = nil
		}
		if elem.DeletionProtection != nil {
			ko.Spec.DeletionProtection = elem.DeletionProtection
		} else {
			ko.Spec.DeletionProtection = nil
		}
		if elem.EarliestRestorableTime != nil {
			ko.Status.EarliestRestorableTime = &metav1.Time{*elem.EarliestRestorableTime}
		} else {
			ko.Status.EarliestRestorableTime = nil
		}
		if elem.EnabledCloudwatchLogsExports != nil {
			ko.Status.EnabledCloudwatchLogsExports = aws.StringSlice(elem.EnabledCloudwatchLogsExports)
		} else {
			ko.Status.EnabledCloudwatchLogsExports = nil
		}
		if elem.Endpoint != nil {
			ko.Status.Endpoint = elem.Endpoint
		} else {
			ko.Status.Endpoint = nil
		}
		if elem.Engine != nil {
			ko.Spec.Engine = elem.Engine
		} else {
			ko.Spec.Engine = nil
		}
		if elem.EngineVersion != nil {
			ko.Spec.EngineVersion = elem.EngineVersion
		} else {
			ko.Spec.EngineVersion = nil
		}
		if elem.HostedZoneId != nil {
			ko.Status.HostedZoneID = elem.HostedZoneId
		} else {
			ko.Status.HostedZoneID = nil
		}
		if elem.KmsKeyId != nil {
			ko.Spec.KMSKeyID = elem.KmsKeyId
		} else {
			ko.Spec.KMSKeyID = nil
		}
		if elem.LatestRestorableTime != nil {
			ko.Status.LatestRestorableTime = &metav1.Time{*elem.LatestRestorableTime}
		} else {
			ko.Status.LatestRestorableTime = nil
		}
		if elem.MasterUsername != nil {
			ko.Spec.MasterUsername = elem.MasterUsername
		} else {
			ko.Spec.MasterUsername = nil
		}
		if elem.MultiAZ != nil {
			ko.Status.MultiAZ = elem.MultiAZ
		} else {
			ko.Status.MultiAZ = nil
		}
		if elem.PercentProgress != nil {
			ko.Status.PercentProgress = elem.PercentProgress
		} else {
			ko.Status.PercentProgress = nil
		}
		if elem.Port != nil {
			portCopy := int64(*elem.Port)
			ko.Spec.Port = &portCopy
		} else {
			ko.Spec.Port = nil
		}
		if elem.PreferredBackupWindow != nil {
			ko.Spec.PreferredBackupWindow = elem.PreferredBackupWindow
		} else {
			ko.Spec.PreferredBackupWindow = nil
		}
		if elem.PreferredMaintenanceWindow != nil {
			ko.Spec.PreferredMaintenanceWindow = elem.PreferredMaintenanceWindow
		} else {
			ko.Spec.PreferredMaintenanceWindow = nil
		}
		if elem.ReadReplicaIdentifiers != nil {
			ko.Status.ReadReplicaIdentifiers = aws.StringSlice(elem.ReadReplicaIdentifiers)
		} else {
			ko.Status.ReadReplicaIdentifiers = nil
		}
		if elem.ReaderEndpoint != nil {
			ko.Status.ReaderEndpoint = elem.ReaderEndpoint
		} else {
			ko.Status.ReaderEndpoint = nil
		}
		if elem.ReplicationSourceIdentifier != nil {
			ko.Status.ReplicationSourceIdentifier = elem.ReplicationSourceIdentifier
		} else {
			ko.Status.ReplicationSourceIdentifier = nil
		}
		if elem.Status != nil {
			ko.Status.Status = elem.Status
		} else {
			ko.Status.Status = nil
		}
		if elem.StorageEncrypted != nil {
			ko.Spec.StorageEncrypted = elem.StorageEncrypted
		} else {
			ko.Spec.StorageEncrypted = nil
		}
		if elem.StorageType != nil {
			ko.Spec.StorageType = elem.StorageType
		} else {
			ko.Spec.StorageType = nil
		}
		if elem.VpcSecurityGroups != nil {
			f32 := []*svcapitypes.VPCSecurityGroupMembership{}
			for _, f32iter := range elem.VpcSecurityGroups {
				f32elem := &svcapitypes.VPCSecurityGroupMembership{}
				if f32iter.Status != nil {
					f32elem.Status = f32iter.Status
				}
				if f32iter.VpcSecurityGroupId != nil {
					f32elem.VPCSecurityGroupID = f32iter.VpcSecurityGroupId
				}
				f32 = append(f32, f32elem)
			}
			ko.Status.VPCSecurityGroups = f32
		} else {
			ko.Status.VPCSecurityGroups = nil
		}
		found = true
		break
	}
	if !found {
		return nil, ackerr.NotFound
	}

	rm.setStatusDefaults(ko)
	if ko.Status.ACKResourceMetadata != nil && ko.Status.ACKResourceMetadata.ARN != nil {
		resourceARN := (*string)(ko.Status.ACKResourceMetadata.ARN)
		tags, err := rm.getTags(ctx, *resourceARN)
		if err != nil {
			return nil, err
		}
		ko.Spec.Tags = tags
	}
	if len(r.ko.Spec.VPCSecurityGroupIDs) > 0 {
		// If the desired resource has security groups specified then update the spec of the latest resource with the
		// value from the status. This is done so that when a cluster is created without security groups and gets a
		// default security group attached to it, it is not overwritten with empty security groups from the
		// desired resource.
		sgIDs := make([]*string, len(ko.Status.VPCSecurityGroups))
		for i, sg := range ko.Status.VPCSecurityGroups {
			id := *sg.VPCSecurityGroupID
			sgIDs[i] = &id
		}
		ko.Spec.VPCSecurityGroupIDs = sgIDs
	}
	if r.ko.Spec.DBClusterParameterGroupName != nil {
		// If the desired resource has db cluster parameter group name specified then update the spec of the latest
		// resource with the value from the status.
		ko.Spec.DBClusterParameterGroupName = ko.Status.DBClusterParameterGroup
	}
	if !clusterAvailable(&resource{ko}) {
		// Setting resource synced condition to false will trigger a requeue of
		// the resource. No need to return a requeue error here.
		ackcondition.SetSynced(&resource{ko}, corev1.ConditionFalse, nil, nil)
	} else {
		ackcondition.SetSynced(&resource{ko}, corev1.ConditionTrue, nil, nil)
	}
	return &resource{ko}, nil
}

// requiredFieldsMissingFromReadManyInput returns true if there are any fields
// for the ReadMany Input shape that are required but not present in the
// resource's Spec or Status
func (rm *resourceManager) requiredFieldsMissingFromReadManyInput(
	r *resource,
) bool {
	return false
}

// newListRequestPayload returns SDK-specific struct for the HTTP request
// payload of the List API call for the resource
func (rm *resourceManager) newListRequestPayload(
	r *resource,
) (*svcsdk.DescribeDBClustersInput, error) {
	res := &svcsdk.DescribeDBClustersInput{}

	if r.ko.Spec.DBClusterIdentifier != nil {
		res.DBClusterIdentifier = r.ko.Spec.DBClusterIdentifier
	}

	return res, nil
}

// sdkCreate creates the supplied resource in the backend AWS service API and
// returns a copy of the resource with resource fields (in both Spec and
// Status) filled in with values from the CREATE API operation's Output shape.
func (rm *resourceManager) sdkCreate(
	ctx context.Context,
	desired *resource,
) (created *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkCreate")
	defer func() {
		exit(err)
	}()
	// if request has SnapshotIdentifier spec, create request will call RestoreDBClusterFromSnapshotWithContext
	// instead of normal create api
	if desired.ko.Spec.SnapshotIdentifier != nil {
		return rm.restoreDbClusterFromSnapshot(ctx, desired)
	}

	input, err := rm.newCreateRequestPayload(ctx, desired)
	if err != nil {
		return nil, err
	}

	var resp *svcsdk.CreateDBClusterOutput
	_ = resp
	resp, err = rm.sdkapi.CreateDBCluster(ctx, input)
	rm.metrics.RecordAPICall("CREATE", "CreateDBCluster", err)
	if err != nil {
		return nil, err
	}
	// Merge in the information we read from the API call above to the copy of
	// the original Kubernetes object we passed to the function
	ko := desired.ko.DeepCopy()

	if resp.DBCluster.AssociatedRoles != nil {
		f0 := []*svcapitypes.DBClusterRole{}
		for _, f0iter := range resp.DBCluster.AssociatedRoles {
			f0elem := &svcapitypes.DBClusterRole{}
			if f0iter.RoleArn != nil {
				f0elem.RoleARN = f0iter.RoleArn
			}
			if f0iter.Status != nil {
				f0elem.Status = f0iter.Status
			}
			f0 = append(f0, f0elem)
		}
		ko.Status.AssociatedRoles = f0
	} else {
		ko.Status.AssociatedRoles = nil
	}
	if resp.DBCluster.AvailabilityZones != nil {
		ko.Spec.AvailabilityZones = aws.StringSlice(resp.DBCluster.AvailabilityZones)
	} else {
		ko.Spec.AvailabilityZones = nil
	}
	if resp.DBCluster.BackupRetentionPeriod != nil {
		backupRetentionPeriodCopy := int64(*resp.DBCluster.BackupRetentionPeriod)
		ko.Spec.BackupRetentionPeriod = &backupRetentionPeriodCopy
	} else {
		ko.Spec.BackupRetentionPeriod = nil
	}
	if resp.DBCluster.CloneGroupId != nil {
		ko.Status.CloneGroupID = resp.DBCluster.CloneGroupId
	} else {
		ko.Status.CloneGroupID = nil
	}
	if resp.DBCluster.ClusterCreateTime != nil {
		ko.Status.ClusterCreateTime = &metav1.Time{*resp.DBCluster.ClusterCreateTime}
	} else {
		ko.Status.ClusterCreateTime = nil
	}
	if ko.Status.ACKResourceMetadata == nil {
		ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
	}
	if resp.DBCluster.DBClusterArn != nil {
		arn := ackv1alpha1.AWSResourceName(*resp.DBCluster.DBClusterArn)
		ko.Status.ACKResourceMetadata.ARN = &arn
	}
	if resp.DBCluster.DBClusterIdentifier != nil {
		ko.Spec.DBClusterIdentifier = resp.DBCluster.DBClusterIdentifier
	} else {
		ko.Spec.DBClusterIdentifier = nil
	}
	if resp.DBCluster.DBClusterMembers != nil {
		f7 := []*svcapitypes.DBClusterMember{}
		for _, f7iter := range resp.DBCluster.DBClusterMembers {
			f7elem := &svcapitypes.DBClusterMember{}
			if f7iter.DBClusterParameterGroupStatus != nil {
				f7elem.DBClusterParameterGroupStatus = f7iter.DBClusterParameterGroupStatus
			}
			if f7iter.DBInstanceIdentifier != nil {
				f7elem.DBInstanceIdentifier = f7iter.DBInstanceIdentifier
			}
			if f7iter.IsClusterWriter != nil {
				f7elem.IsClusterWriter = f7iter.IsClusterWriter
			}
			if f7iter.PromotionTier != nil {
				promotionTierCopy := int64(*f7iter.PromotionTier)
				f7elem.PromotionTier = &promotionTierCopy
			}
			f7 = append(f7, f7elem)
		}
		ko.Status.DBClusterMembers = f7
	} else {
		ko.Status.DBClusterMembers = nil
	}
	if resp.DBCluster.DBClusterParameterGroup != nil {
		ko.Status.DBClusterParameterGroup = resp.DBCluster.DBClusterParameterGroup
	} else {
		ko.Status.DBClusterParameterGroup = nil
	}
	if resp.DBCluster.DBSubnetGroup != nil {
		ko.Status.DBSubnetGroup = resp.DBCluster.DBSubnetGroup
	} else {
		ko.Status.DBSubnetGroup = nil
	}
	if resp.DBCluster.DbClusterResourceId != nil {
		ko.Status.DBClusterResourceID = resp.DBCluster.DbClusterResourceId
	} else {
		ko.Status.DBClusterResourceID = nil
	}
	if resp.DBCluster.DeletionProtection != nil {
		ko.Spec.DeletionProtection = resp.DBCluster.DeletionProtection
	} else {
		ko.Spec.DeletionProtection = nil
	}
	if resp.DBCluster.EarliestRestorableTime != nil {
		ko.Status.EarliestRestorableTime = &metav1.Time{*resp.DBCluster.EarliestRestorableTime}
	} else {
		ko.Status.EarliestRestorableTime = nil
	}
	if resp.DBCluster.EnabledCloudwatchLogsExports != nil {
		ko.Status.EnabledCloudwatchLogsExports = aws.StringSlice(resp.DBCluster.EnabledCloudwatchLogsExports)
	} else {
		ko.Status.EnabledCloudwatchLogsExports = nil
	}
	if resp.DBCluster.Endpoint != nil {
		ko.Status.Endpoint = resp.DBCluster.Endpoint
	} else {
		ko.Status.Endpoint = nil
	}
	if resp.DBCluster.Engine != nil {
		ko.Spec.Engine = resp.DBCluster.Engine
	} else {
		ko.Spec.Engine = nil
	}
	if resp.DBCluster.EngineVersion != nil {
		ko.Spec.EngineVersion = resp.DBCluster.EngineVersion
	} else {
		ko.Spec.EngineVersion = nil
	}
	if resp.DBCluster.HostedZoneId != nil {
		ko.Status.HostedZoneID = resp.DBCluster.HostedZoneId
	} else {
		ko.Status.HostedZoneID = nil
	}
	if resp.DBCluster.KmsKeyId != nil {
		ko.Spec.KMSKeyID = resp.DBCluster.KmsKeyId
	} else {
		ko.Spec.KMSKeyID = nil
	}
	if resp.DBCluster.LatestRestorableTime != nil {
		ko.Status.LatestRestorableTime = &metav1.Time{*resp.DBCluster.LatestRestorableTime}
	} else {
		ko.Status.LatestRestorableTime = nil
	}
	if resp.DBCluster.MasterUsername != nil {
		ko.Spec.MasterUsername = resp.DBCluster.MasterUsername
	} else {
		ko.Spec.MasterUsername = nil
	}
	if resp.DBCluster.MultiAZ != nil {
		ko.Status.MultiAZ = resp.DBCluster.MultiAZ
	} else {
		ko.Status.MultiAZ = nil
	}
	if resp.DBCluster.PercentProgress != nil {
		ko.Status.PercentProgress = resp.DBCluster.PercentProgress
	} else {
		ko.Status.PercentProgress = nil
	}
	if resp.DBCluster.Port != nil {
		portCopy := int64(*resp.DBCluster.Port)
		ko.Spec.Port = &portCopy
	} else {
		ko.Spec.Port = nil
	}
	if resp.DBCluster.PreferredBackupWindow != nil {
		ko.Spec.PreferredBackupWindow = resp.DBCluster.PreferredBackupWindow
	} else {
		ko.Spec.PreferredBackupWindow = nil
	}
	if resp.DBCluster.PreferredMaintenanceWindow != nil {
		ko.Spec.PreferredMaintenanceWindow = resp.DBCluster.PreferredMaintenanceWindow
	} else {
		ko.Spec.PreferredMaintenanceWindow = nil
	}
	if resp.DBCluster.ReadReplicaIdentifiers != nil {
		ko.Status.ReadReplicaIdentifiers = aws.StringSlice(resp.DBCluster.ReadReplicaIdentifiers)
	} else {
		ko.Status.ReadReplicaIdentifiers = nil
	}
	if resp.DBCluster.ReaderEndpoint != nil {
		ko.Status.ReaderEndpoint = resp.DBCluster.ReaderEndpoint
	} else {
		ko.Status.ReaderEndpoint = nil
	}
	if resp.DBCluster.ReplicationSourceIdentifier != nil {
		ko.Status.ReplicationSourceIdentifier = resp.DBCluster.ReplicationSourceIdentifier
	} else {
		ko.Status.ReplicationSourceIdentifier = nil
	}
	if resp.DBCluster.Status != nil {
		ko.Status.Status = resp.DBCluster.Status
	} else {
		ko.Status.Status = nil
	}
	if resp.DBCluster.StorageEncrypted != nil {
		ko.Spec.StorageEncrypted = resp.DBCluster.StorageEncrypted
	} else {
		ko.Spec.StorageEncrypted = nil
	}
	if resp.DBCluster.StorageType != nil {
		ko.Spec.StorageType = resp.DBCluster.StorageType
	} else {
		ko.Spec.StorageType = nil
	}
	if resp.DBCluster.VpcSecurityGroups != nil {
		f32 := []*svcapitypes.VPCSecurityGroupMembership{}
		for _, f32iter := range resp.DBCluster.VpcSecurityGroups {
			f32elem := &svcapitypes.VPCSecurityGroupMembership{}
			if f32iter.Status != nil {
				f32elem.Status = f32iter.Status
			}
			if f32iter.VpcSecurityGroupId != nil {
				f32elem.VPCSecurityGroupID = f32iter.VpcSecurityGroupId
			}
			f32 = append(f32, f32elem)
		}
		ko.Status.VPCSecurityGroups = f32
	} else {
		ko.Status.VPCSecurityGroups = nil
	}

	rm.setStatusDefaults(ko)
	// We expect the DB cluster to be in 'creating' status since we just
	// issued the call to create it, but I suppose it doesn't hurt to check
	// here.
	if clusterCreating(&resource{ko}) {
		// Setting resource synced condition to false will trigger a requeue of
		// the resource. No need to return a requeue error here.
		ackcondition.SetSynced(&resource{ko}, corev1.ConditionFalse, nil, nil)
		return &resource{ko}, nil
	}

	return &resource{ko}, nil
}

// newCreateRequestPayload returns an SDK-specific struct for the HTTP request
// payload of the Create API call for the resource
func (rm *resourceManager) newCreateRequestPayload(
	ctx context.Context,
	r *resource,
) (*svcsdk.CreateDBClusterInput, error) {
	res := &svcsdk.CreateDBClusterInput{}

	if r.ko.Spec.AvailabilityZones != nil {
		res.AvailabilityZones = aws.ToStringSlice(r.ko.Spec.AvailabilityZones)
	}
	if r.ko.Spec.BackupRetentionPeriod != nil {
		backupRetentionPeriodCopy0 := *r.ko.Spec.BackupRetentionPeriod
		if backupRetentionPeriodCopy0 > math.MaxInt32 || backupRetentionPeriodCopy0 < math.MinInt32 {
			return nil, fmt.Errorf("error: field BackupRetentionPeriod is of type int32")
		}
		backupRetentionPeriodCopy := int32(backupRetentionPeriodCopy0)
		res.BackupRetentionPeriod = &backupRetentionPeriodCopy
	}
	if r.ko.Spec.DBClusterIdentifier != nil {
		res.DBClusterIdentifier = r.ko.Spec.DBClusterIdentifier
	}
	if r.ko.Spec.DBClusterParameterGroupName != nil {
		res.DBClusterParameterGroupName = r.ko.Spec.DBClusterParameterGroupName
	}
	if r.ko.Spec.DBSubnetGroupName != nil {
		res.DBSubnetGroupName = r.ko.Spec.DBSubnetGroupName
	}
	if r.ko.Spec.DeletionProtection != nil {
		res.DeletionProtection = r.ko.Spec.DeletionProtection
	}
	if r.ko.Spec.EnableCloudwatchLogsExports != nil {
		res.EnableCloudwatchLogsExports = aws.ToStringSlice(r.ko.Spec.EnableCloudwatchLogsExports)
	}
	if r.ko.Spec.Engine != nil {
		res.Engine = r.ko.Spec.Engine
	}
	if r.ko.Spec.EngineVersion != nil {
		res.EngineVersion = r.ko.Spec.EngineVersion
	}
	if r.ko.Spec.GlobalClusterIdentifier != nil {
		res.GlobalClusterIdentifier = r.ko.Spec.GlobalClusterIdentifier
	}
	if r.ko.Spec.KMSKeyID != nil {
		res.KmsKeyId = r.ko.Spec.KMSKeyID
	}
	if r.ko.Spec.MasterUserPassword != nil {
		tmpSecret, err := rm.rr.SecretValueFromReference(ctx, r.ko.Spec.MasterUserPassword)
		if err != nil {
			return nil, ackrequeue.Needed(err)
		}
		if tmpSecret != "" {
			res.MasterUserPassword = aws.String(tmpSecret)
		}
	}
	if r.ko.Spec.MasterUsername != nil {
		res.MasterUsername = r.ko.Spec.MasterUsername
	}
	if r.ko.Spec.Port != nil {
		portCopy0 := *r.ko.Spec.Port
		if portCopy0 > math.MaxInt32 || portCopy0 < math.MinInt32 {
			return nil, fmt.Errorf("error: field Port is of type int32")
		}
		portCopy := int32(portCopy0)
		res.Port = &portCopy
	}
	if r.ko.Spec.PreSignedURL != nil {
		res.PreSignedUrl = r.ko.Spec.PreSignedURL
	}
	if r.ko.Spec.PreferredBackupWindow != nil {
		res.PreferredBackupWindow = r.ko.Spec.PreferredBackupWindow
	}
	if r.ko.Spec.PreferredMaintenanceWindow != nil {
		res.PreferredMaintenanceWindow = r.ko.Spec.PreferredMaintenanceWindow
	}
	if r.ko.Spec.SourceRegion != nil {
		res.SourceRegion = r.ko.Spec.SourceRegion
	}
	if r.ko.Spec.StorageEncrypted != nil {
		res.StorageEncrypted = r.ko.Spec.StorageEncrypted
	}
	if r.ko.Spec.StorageType != nil {
		res.StorageType = r.ko.Spec.StorageType
	}
	if r.ko.Spec.Tags != nil {
		f21 := []svcsdktypes.Tag{}
		for _, f21iter := range r.ko.Spec.Tags {
			f21elem := &svcsdktypes.Tag{}
			if f21iter.Key != nil {
				f21elem.Key = f21iter.Key
			}
			if f21iter.Value != nil {
				f21elem.Value = f21iter.Value
			}
			f21 = append(f21, *f21elem)
		}
		res.Tags = f21
	}
	if r.ko.Spec.VPCSecurityGroupIDs != nil {
		res.VpcSecurityGroupIds = aws.ToStringSlice(r.ko.Spec.VPCSecurityGroupIDs)
	}

	return res, nil
}

// sdkUpdate patches the supplied resource in the backend AWS service API and
// returns a new resource with updated fields.
func (rm *resourceManager) sdkUpdate(
	ctx context.Context,
	desired *resource,
	latest *resource,
	delta *ackcompare.Delta,
) (*resource, error) {
	return rm.customUpdate(ctx, desired, latest, delta)
}

// sdkDelete deletes the supplied resource in the backend AWS service API
func (rm *resourceManager) sdkDelete(
	ctx context.Context,
	r *resource,
) (latest *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkDelete")
	defer func() {
		exit(err)
	}()
	if clusterDeleting(r) {
		return r, requeueWaitWhileDeleting
	}

	input, err := rm.newDeleteRequestPayload(r)
	if err != nil {
		return nil, err
	}
	var resp *svcsdk.DeleteDBClusterOutput
	_ = resp
	resp, err = rm.sdkapi.DeleteDBCluster(ctx, input)
	rm.metrics.RecordAPICall("DELETE", "DeleteDBCluster", err)
	return nil, err
}

// newDeleteRequestPayload returns an SDK-specific struct for the HTTP request
// payload of the Delete API call for the resource
func (rm *resourceManager) newDeleteRequestPayload(
	r *resource,
) (*svcsdk.DeleteDBClusterInput, error) {
	res := &svcsdk.DeleteDBClusterInput{}

	if r.ko.Spec.DBClusterIdentifier != nil {
		res.DBClusterIdentifier = r.ko.Spec.DBClusterIdentifier
	}
	res.SkipFinalSnapshot = aws.Bool(true)

	return res, nil
}

// setStatusDefaults sets default properties into supplied custom resource
func (rm *resourceManager) setStatusDefaults(
	ko *svcapitypes.DBCluster,
) {
	if ko.Status.ACKResourceMetadata == nil {
		ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
	}
	if ko.Status.ACKResourceMetadata.Region == nil {
		ko.Status.ACKResourceMetadata.Region = &rm.awsRegion
	}
	if ko.Status.ACKResourceMetadata.OwnerAccountID == nil {
		ko.Status.ACKResourceMetadata.OwnerAccountID = &rm.awsAccountID
	}
	if ko.Status.Conditions == nil {
		ko.Status.Conditions = []*ackv1alpha1.Condition{}
	}
}

// updateConditions returns updated resource, true; if conditions were updated
// else it returns nil, false
func (rm *resourceManager) updateConditions(
	r *resource,
	onSuccess bool,
	err error,
) (*resource, bool) {
	ko := r.ko.DeepCopy()
	rm.setStatusDefaults(ko)

	// Terminal condition
	var terminalCondition *ackv1alpha1.Condition = nil
	var recoverableCondition *ackv1alpha1.Condition = nil
	var syncCondition *ackv1alpha1.Condition = nil
	for _, condition := range ko.Status.Conditions {
		if condition.Type == ackv1alpha1.ConditionTypeTerminal {
			terminalCondition = condition
		}
		if condition.Type == ackv1alpha1.ConditionTypeRecoverable {
			recoverableCondition = condition
		}
		if condition.Type == ackv1alpha1.ConditionTypeResourceSynced {
			syncCondition = condition
		}
	}
	var termError *ackerr.TerminalError
	if rm.terminalAWSError(err) || err == ackerr.SecretTypeNotSupported || err == ackerr.SecretNotFound || errors.As(err, &termError) {
		if terminalCondition == nil {
			terminalCondition = &ackv1alpha1.Condition{
				Type: ackv1alpha1.ConditionTypeTerminal,
			}
			ko.Status.Conditions = append(ko.Status.Conditions, terminalCondition)
		}
		var errorMessage = ""
		if err == ackerr.SecretTypeNotSupported || err == ackerr.SecretNotFound || errors.As(err, &termError) {
			errorMessage = err.Error()
		} else {
			awsErr, _ := ackerr.AWSError(err)
			errorMessage = awsErr.Error()
		}
		terminalCondition.Status = corev1.ConditionTrue
		terminalCondition.Message = &errorMessage
	} else {
		// Clear the terminal condition if no longer present
		if terminalCondition != nil {
			terminalCondition.Status = corev1.ConditionFalse
			terminalCondition.Message = nil
		}
		// Handling Recoverable Conditions
		if err != nil {
			if recoverableCondition == nil {
				// Add a new Condition containing a non-terminal error
				recoverableCondition = &ackv1alpha1.Condition{
					Type: ackv1alpha1.ConditionTypeRecoverable,
				}
				ko.Status.Conditions = append(ko.Status.Conditions, recoverableCondition)
			}
			recoverableCondition.Status = corev1.ConditionTrue
			awsErr, _ := ackerr.AWSError(err)
			errorMessage := err.Error()
			if awsErr != nil {
				errorMessage = awsErr.Error()
			}
			recoverableCondition.Message = &errorMessage
		} else if recoverableCondition != nil {
			recoverableCondition.Status = corev1.ConditionFalse
			recoverableCondition.Message = nil
		}
	}
	// Required to avoid the "declared but not used" error in the default case
	_ = syncCondition
	if terminalCondition != nil || recoverableCondition != nil || syncCondition != nil {
		return &resource{ko}, true // updated
	}
	return nil, false // not updated
}

// terminalAWSError returns awserr, true; if the supplied error is an aws Error type
// and if the exception indicates that it is a Terminal exception
// 'Terminal' exception are specified in generator configuration
func (rm *resourceManager) terminalAWSError(err error) bool {
	if err == nil {
		return false
	}

	var terminalErr smithy.APIError
	if !errors.As(err, &terminalErr) {
		return false
	}
	switch terminalErr.ErrorCode() {
	case "DBClusterQuotaExceededFault",
		"DBSubnetGroupDoesNotCoverEnoughAZs",
		"InsufficientStorageClusterCapacity",
		"InvalidParameter",
		"InvalidParameterValue",
		"InvalidParameterCombination",
		"InvalidSubnet",
		"StorageQuotaExceeded":
		return true
	default:
		return false
	}
}

// newRestoreDBClusterFromSnapshotInput returns a RestoreDBClusterFromSnapshotInput object
// with each the field set by the corresponding configuration's fields.
func (rm *resourceManager) newRestoreDBClusterFromSnapshotInput(
	r *resource,
) (*svcsdk.RestoreDBClusterFromSnapshotInput, error) {
	res := &svcsdk.RestoreDBClusterFromSnapshotInput{}

	if r.ko.Spec.AvailabilityZones != nil {
		res.AvailabilityZones = aws.ToStringSlice(r.ko.Spec.AvailabilityZones)
	}
	if r.ko.Spec.DBClusterIdentifier != nil {
		res.DBClusterIdentifier = r.ko.Spec.DBClusterIdentifier
	}
	if r.ko.Spec.DBClusterParameterGroupName != nil {
		res.DBClusterParameterGroupName = r.ko.Spec.DBClusterParameterGroupName
	}
	if r.ko.Spec.DBSubnetGroupName != nil {
		res.DBSubnetGroupName = r.ko.Spec.DBSubnetGroupName
	}
	if r.ko.Spec.DeletionProtection != nil {
		res.DeletionProtection = r.ko.Spec.DeletionProtection
	}
	if r.ko.Spec.EnableCloudwatchLogsExports != nil {
		res.EnableCloudwatchLogsExports = aws.ToStringSlice(r.ko.Spec.EnableCloudwatchLogsExports)
	}
	if r.ko.Spec.Engine != nil {
		res.Engine = r.ko.Spec.Engine
	}
	if r.ko.Spec.EngineVersion != nil {
		res.EngineVersion = r.ko.Spec.EngineVersion
	}
	if r.ko.Spec.KMSKeyID != nil {
		res.KmsKeyId = r.ko.Spec.KMSKeyID
	}
	if r.ko.Spec.Port != nil {
		portCopy0 := *r.ko.Spec.Port
		if portCopy0 > math.MaxInt32 || portCopy0 < math.MinInt32 {
			return nil, fmt.Errorf("error: field Port is of type int32")
		}
		portCopy := int32(portCopy0)
		res.Port = &portCopy
	}
	if r.ko.Spec.SnapshotIdentifier != nil {
		res.SnapshotIdentifier = r.ko.Spec.SnapshotIdentifier
	}
	if r.ko.Spec.StorageType != nil {
		res.StorageType = r.ko.Spec.StorageType
	}
	if r.ko.Spec.Tags != nil {
		resf12 := []svcsdktypes.Tag{}
		for _, resf12iter := range r.ko.Spec.Tags {
			resf12elem := &svcsdktypes.Tag{}
			if resf12iter.Key != nil {
				resf12elem.Key = resf12iter.Key
			}
			if resf12iter.Value != nil {
				resf12elem.Value = resf12iter.Value
			}
			resf12 = append(resf12, *resf12elem)
		}
		res.Tags = resf12
	}
	if r.ko.Spec.VPCSecurityGroupIDs != nil {
		res.VpcSecurityGroupIds = aws.ToStringSlice(r.ko.Spec.VPCSecurityGroupIDs)
	}

	return res, nil
}

// setResourceFromRestoreDBClusterFromSnapshotOutput sets a resource RestoreDBClusterFromSnapshotOutput type
// given the SDK type.
func (rm *resourceManager) setResourceFromRestoreDBClusterFromSnapshotOutput(
	r *resource,
	resp *svcsdk.RestoreDBClusterFromSnapshotOutput,
) {

	if resp.DBCluster.AssociatedRoles != nil {
		f0 := []*svcapitypes.DBClusterRole{}
		for _, f0iter := range resp.DBCluster.AssociatedRoles {
			f0elem := &svcapitypes.DBClusterRole{}
			if f0iter.RoleArn != nil {
				f0elem.RoleARN = f0iter.RoleArn
			}
			if f0iter.Status != nil {
				f0elem.Status = f0iter.Status
			}
			f0 = append(f0, f0elem)
		}
		r.ko.Status.AssociatedRoles = f0
	} else {
		r.ko.Status.AssociatedRoles = nil
	}
	if resp.DBCluster.AvailabilityZones != nil {
		r.ko.Spec.AvailabilityZones = aws.StringSlice(resp.DBCluster.AvailabilityZones)
	} else {
		r.ko.Spec.AvailabilityZones = nil
	}
	if resp.DBCluster.BackupRetentionPeriod != nil {
		backupRetentionPeriodCopy := int64(*resp.DBCluster.BackupRetentionPeriod)
		r.ko.Spec.BackupRetentionPeriod = &backupRetentionPeriodCopy
	} else {
		r.ko.Spec.BackupRetentionPeriod = nil
	}
	if resp.DBCluster.CloneGroupId != nil {
		r.ko.Status.CloneGroupID = resp.DBCluster.CloneGroupId
	} else {
		r.ko.Status.CloneGroupID = nil
	}
	if resp.DBCluster.ClusterCreateTime != nil {
		r.ko.Status.ClusterCreateTime = &metav1.Time{*resp.DBCluster.ClusterCreateTime}
	} else {
		r.ko.Status.ClusterCreateTime = nil
	}
	if r.ko.Status.ACKResourceMetadata == nil {
		r.ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
	}
	if resp.DBCluster.DBClusterArn != nil {
		arn := ackv1alpha1.AWSResourceName(*resp.DBCluster.DBClusterArn)
		r.ko.Status.ACKResourceMetadata.ARN = &arn
	}
	if resp.DBCluster.DBClusterIdentifier != nil {
		r.ko.Spec.DBClusterIdentifier = resp.DBCluster.DBClusterIdentifier
	} else {
		r.ko.Spec.DBClusterIdentifier = nil
	}
	if resp.DBCluster.DBClusterMembers != nil {
		f7 := []*svcapitypes.DBClusterMember{}
		for _, f7iter := range resp.DBCluster.DBClusterMembers {
			f7elem := &svcapitypes.DBClusterMember{}
			if f7iter.DBClusterParameterGroupStatus != nil {
				f7elem.DBClusterParameterGroupStatus = f7iter.DBClusterParameterGroupStatus
			}
			if f7iter.DBInstanceIdentifier != nil {
				f7elem.DBInstanceIdentifier = f7iter.DBInstanceIdentifier
			}
			if f7iter.IsClusterWriter != nil {
				f7elem.IsClusterWriter = f7iter.IsClusterWriter
			}
			if f7iter.PromotionTier != nil {
				promotionTierCopy := int64(*f7iter.PromotionTier)
				f7elem.PromotionTier = &promotionTierCopy
			}
			f7 = append(f7, f7elem)
		}
		r.ko.Status.DBClusterMembers = f7
	} else {
		r.ko.Status.DBClusterMembers = nil
	}
	if resp.DBCluster.DBClusterParameterGroup != nil {
		r.ko.Status.DBClusterParameterGroup = resp.DBCluster.DBClusterParameterGroup
	} else {
		r.ko.Status.DBClusterParameterGroup = nil
	}
	if resp.DBCluster.DBSubnetGroup != nil {
		r.ko.Status.DBSubnetGroup = resp.DBCluster.DBSubnetGroup
	} else {
		r.ko.Status.DBSubnetGroup = nil
	}
	if resp.DBCluster.DbClusterResourceId != nil {
		r.ko.Status.DBClusterResourceID = resp.DBCluster.DbClusterResourceId
	} else {
		r.ko.Status.DBClusterResourceID = nil
	}
	if resp.DBCluster.DeletionProtection != nil {
		r.ko.Spec.DeletionProtection = resp.DBCluster.DeletionProtection
	} else {
		r.ko.Spec.DeletionProtection = nil
	}
	if resp.DBCluster.EarliestRestorableTime != nil {
		r.ko.Status.EarliestRestorableTime = &metav1.Time{*resp.DBCluster.EarliestRestorableTime}
	} else {
		r.ko.Status.EarliestRestorableTime = nil
	}
	if resp.DBCluster.EnabledCloudwatchLogsExports != nil {
		r.ko.Status.EnabledCloudwatchLogsExports = aws.StringSlice(resp.DBCluster.EnabledCloudwatchLogsExports)
	} else {
		r.ko.Status.EnabledCloudwatchLogsExports = nil
	}
	if resp.DBCluster.Endpoint != nil {
		r.ko.Status.Endpoint = resp.DBCluster.Endpoint
	} else {
		r.ko.Status.Endpoint = nil
	}
	if resp.DBCluster.Engine != nil {
		r.ko.Spec.Engine = resp.DBCluster.Engine
	} else {
		r.ko.Spec.Engine = nil
	}
	if resp.DBCluster.EngineVersion != nil {
		r.ko.Spec.EngineVersion = resp.DBCluster.EngineVersion
	} else {
		r.ko.Spec.EngineVersion = nil
	}
	if resp.DBCluster.HostedZoneId != nil {
		r.ko.Status.HostedZoneID = resp.DBCluster.HostedZoneId
	} else {
		r.ko.Status.HostedZoneID = nil
	}
	if resp.DBCluster.KmsKeyId != nil {
		r.ko.Spec.KMSKeyID = resp.DBCluster.KmsKeyId
	} else {
		r.ko.Spec.KMSKeyID = nil
	}
	if resp.DBCluster.LatestRestorableTime != nil {
		r.ko.Status.LatestRestorableTime = &metav1.Time{*resp.DBCluster.LatestRestorableTime}
	} else {
		r.ko.Status.LatestRestorableTime = nil
	}
	if resp.DBCluster.MasterUsername != nil {
		r.ko.Spec.MasterUsername = resp.DBCluster.MasterUsername
	} else {
		r.ko.Spec.MasterUsername = nil
	}
	if resp.DBCluster.MultiAZ != nil {
		r.ko.Status.MultiAZ = resp.DBCluster.MultiAZ
	} else {
		r.ko.Status.MultiAZ = nil
	}
	if resp.DBCluster.PercentProgress != nil {
		r.ko.Status.PercentProgress = resp.DBCluster.PercentProgress
	} else {
		r.ko.Status.PercentProgress = nil
	}
	if resp.DBCluster.Port != nil {
		portCopy := int64(*resp.DBCluster.Port)
		r.ko.Spec.Port = &portCopy
	} else {
		r.ko.Spec.Port = nil
	}
	if resp.DBCluster.PreferredBackupWindow != nil {
		r.ko.Spec.PreferredBackupWindow = resp.DBCluster.PreferredBackupWindow
	} else {
		r.ko.Spec.PreferredBackupWindow = nil
	}
	if resp.DBCluster.PreferredMaintenanceWindow != nil {
		r.ko.Spec.PreferredMaintenanceWindow = resp.DBCluster.PreferredMaintenanceWindow
	} else {
		r.ko.Spec.PreferredMaintenanceWindow = nil
	}
	if resp.DBCluster.ReadReplicaIdentifiers != nil {
		r.ko.Status.ReadReplicaIdentifiers = aws.StringSlice(resp.DBCluster.ReadReplicaIdentifiers)
	} else {
		r.ko.Status.ReadReplicaIdentifiers = nil
	}
	if resp.DBCluster.ReaderEndpoint != nil {
		r.ko.Status.ReaderEndpoint = resp.DBCluster.ReaderEndpoint
	} else {
		r.ko.Status.ReaderEndpoint = nil
	}
	if resp.DBCluster.ReplicationSourceIdentifier != nil {
		r.ko.Status.ReplicationSourceIdentifier = resp.DBCluster.ReplicationSourceIdentifier
	} else {
		r.ko.Status.ReplicationSourceIdentifier = nil
	}
	if resp.DBCluster.Status != nil {
		r.ko.Status.Status = resp.DBCluster.Status
	} else {
		r.ko.Status.Status = nil
	}
	if resp.DBCluster.StorageEncrypted != nil {
		r.ko.Spec.StorageEncrypted = resp.DBCluster.StorageEncrypted
	} else {
		r.ko.Spec.StorageEncrypted = nil
	}
	if resp.DBCluster.StorageType != nil {
		r.ko.Spec.StorageType = resp.DBCluster.StorageType
	} else {
		r.ko.Spec.StorageType = nil
	}
	if resp.DBCluster.VpcSecurityGroups != nil {
		f32 := []*svcapitypes.VPCSecurityGroupMembership{}
		for _, f32iter := range resp.DBCluster.VpcSecurityGroups {
			f32elem := &svcapitypes.VPCSecurityGroupMembership{}
			if f32iter.Status != nil {
				f32elem.Status = f32iter.Status
			}
			if f32iter.VpcSecurityGroupId != nil {
				f32elem.VPCSecurityGroupID = f32iter.VpcSecurityGroupId
			}
			f32 = append(f32, f32elem)
		}
		r.ko.Status.VPCSecurityGroups = f32
	} else {
		r.ko.Status.VPCSecurityGroups = nil
	}

}
